{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b607aca7",
   "metadata": {},
   "source": [
    "> NOTA: esta notebook importa funciones de notebook.ipynb.\n",
    "> Posiblemente no funcione en Google Colab sin configuraci칩n adicional.\n",
    "\n",
    "# 游댍 Grid Search\n",
    "\n",
    "Se implementa una b칰squeda exhaustiva (grid search) de combinaciones de hiperpar치metros para encontrar la mejor configuraci칩n del modelo y analizar el impacto de los hiperpar치metros en el entrenamiento. Se exploran diferentes:\n",
    "\n",
    "- Arquitecturas de red (capas ocultas),\n",
    "- Tama침os de batch para SGD, y\n",
    "- Tasas de decrecimiento del learning rate.\n",
    "\n",
    "Los resultados se guardan en un CSV para an치lisis posterior y se generan visualizaciones de cada experimento.\n",
    "\n",
    "Primero se deben importar las funciones y variables de `notebook.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dbf488",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 174\u001b[39m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal experiments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df_results\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m grid_search_minibatch(\u001b[43mdatasets\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def grid_search_minibatch(datasets):\n",
    "    \"\"\"\n",
    "    Performs grid search over hyperparameters using train_with_minibatch_sgd.\n",
    "\n",
    "    Explores:\n",
    "    - Hidden layer 1 sizes: [50, 40, 30, 20, 10]\n",
    "    - Hidden layer 2 sizes: [25, 20, 15, 10, 5]\n",
    "    - Decay rates: [0.01, 0.02, 0.05]\n",
    "    - Batch sizes: [16, 8]\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with results for all experiments saved to 'grid_search_results.csv'\n",
    "    \"\"\"\n",
    "    # Define hyperparameter grid\n",
    "    h1_sizes = [50, 40, 30, 20, 10]\n",
    "    h2_sizes = [25, 20, 15, 10, 5]\n",
    "    decay_rates = [0.01, 0.02, 0.05]\n",
    "    batch_sizes = [16, 8]\n",
    "\n",
    "    # Fixed hyperparameters\n",
    "    initial_lr = 0.1\n",
    "    min_lr = 0.05\n",
    "    tolerance = 1e-6\n",
    "\n",
    "    # Get sorted dataset keys for consistent ordering\n",
    "    dataset_keys = sorted(datasets.keys())\n",
    "\n",
    "    # Results storage\n",
    "    all_results = []\n",
    "\n",
    "    # Total number of experiments\n",
    "    total_experiments = (\n",
    "        len(h1_sizes) * len(h2_sizes) * len(decay_rates) * len(batch_sizes)\n",
    "    )\n",
    "    experiment_num = 0\n",
    "\n",
    "    print(f\"Starting grid search: {total_experiments} total experiments\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Iterate over all combinations\n",
    "    for h1 in h1_sizes:\n",
    "        for h2 in h2_sizes:\n",
    "            for decay in decay_rates:\n",
    "                for batch_size in batch_sizes:\n",
    "                    experiment_num += 1\n",
    "\n",
    "                    # Create experiment name\n",
    "                    decay_pct = int(decay * 100)\n",
    "                    experiment_name = f\"lr{initial_lr:.2f}_decay{decay_pct}pct_bs{batch_size}_layers100-{h1}-{h2}-3\"\n",
    "\n",
    "                    print(\n",
    "                        f\"\\n[{experiment_num}/{total_experiments}] Starting: {experiment_name}\"\n",
    "                    )\n",
    "\n",
    "                    # Reset RNG for reproducibility\n",
    "                    reset_rng()\n",
    "\n",
    "                    # Create MLP factory\n",
    "                    def mlp_factory():\n",
    "                        return MLP2(\n",
    "                            layers=(100, h1, h2, 3),\n",
    "                            activation_type=\"sigmoid\",\n",
    "                            learning_rate=initial_lr,\n",
    "                            momentum=0.1,\n",
    "                        )\n",
    "\n",
    "                    # Train with minibatch SGD\n",
    "                    results = train_with_minibatch_sgd(\n",
    "                        datasets=datasets,\n",
    "                        mlp_factory=mlp_factory,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        initial_lr=initial_lr,\n",
    "                        decay=decay,\n",
    "                        min_lr=min_lr,\n",
    "                        tolerance=tolerance,\n",
    "                    )\n",
    "\n",
    "                    # Build result row\n",
    "                    row = {\"experiment\": experiment_name}\n",
    "\n",
    "                    # Track metrics for finding best dataset\n",
    "                    dataset_metrics = {}\n",
    "\n",
    "                    # Process each dataset result\n",
    "                    for res in results:\n",
    "                        dataset_name = res[\"dataset_name\"]\n",
    "                        mlp = res[\"mlp\"]\n",
    "                        val_losses = res[\"val_losses\"]\n",
    "\n",
    "                        # Compute accuracy for this dataset\n",
    "                        _, val_data = datasets[dataset_name]\n",
    "                        n = len(val_data)\n",
    "                        correct = 0\n",
    "                        for i in range(n):\n",
    "                            sample = np.array(\n",
    "                                val_data.iloc[i, :100].values, dtype=np.float64\n",
    "                            )\n",
    "                            true_class = val_data.iloc[i, 100]\n",
    "                            if mlp.classify(sample) == true_class:\n",
    "                                correct += 1\n",
    "                        accuracy = correct / n\n",
    "\n",
    "                        # Compute loss metrics\n",
    "                        val_loss_mean = np.mean(val_losses)\n",
    "                        val_loss_final = val_losses[-1]\n",
    "\n",
    "                        # Store in row\n",
    "                        row[f\"{dataset_name}_accuracy\"] = accuracy\n",
    "                        row[f\"{dataset_name}_val_loss_mean\"] = val_loss_mean\n",
    "                        row[f\"{dataset_name}_val_loss_final\"] = val_loss_final\n",
    "\n",
    "                        # Track for best dataset\n",
    "                        dataset_metrics[dataset_name] = val_loss_mean\n",
    "\n",
    "                    # Find best dataset (minimum mean validation loss)\n",
    "                    best_dataset = min(dataset_metrics, key=dataset_metrics.get)\n",
    "                    row[\"best_dataset_by_min_val_loss\"] = best_dataset\n",
    "\n",
    "                    # Add to results\n",
    "                    all_results.append(row)\n",
    "\n",
    "                    # Plot training evolution for this experiment\n",
    "                    fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n",
    "                    fig.suptitle(\n",
    "                        f\"Experiment: {experiment_name}\", fontsize=16, fontweight=\"bold\"\n",
    "                    )\n",
    "\n",
    "                    for idx, res in enumerate(results):\n",
    "                        ax = axes[idx // 3][idx % 3]\n",
    "                        ax.plot(\n",
    "                            res[\"epochs\"],\n",
    "                            res[\"train_losses\"],\n",
    "                            color=\"orangered\",\n",
    "                            label=\"Training Loss\",\n",
    "                        )\n",
    "                        ax.plot(\n",
    "                            res[\"epochs\"],\n",
    "                            res[\"val_losses\"],\n",
    "                            color=\"seagreen\",\n",
    "                            linestyle=\"--\",\n",
    "                            label=\"Validation Loss\",\n",
    "                        )\n",
    "\n",
    "                        ax.set_yscale(\"log\")\n",
    "                        ax.set_title(f\"Dataset '{res['dataset_name']}'\", fontsize=10)\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                        ax.set_xlabel(\"Epochs\")\n",
    "\n",
    "                        # Set loss label on first column\n",
    "                        if idx % 3 == 0:\n",
    "                            ax.set_ylabel(\"Loss\")\n",
    "\n",
    "                        # Add legend only to the first subplot\n",
    "                        if idx == 0:\n",
    "                            ax.legend(loc=\"upper right\", fontsize=8)\n",
    "\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "\n",
    "                    print(f\"Experiment {experiment_name} finished\")\n",
    "                    print(\n",
    "                        f\"  - Best dataset: {best_dataset} (val_loss_mean={dataset_metrics[best_dataset]:.6f})\"\n",
    "                    )\n",
    "\n",
    "    # Create DataFrame and save to CSV\n",
    "    df_results = pd.DataFrame(all_results)\n",
    "    csv_filename = \"grid_search_results.csv\"\n",
    "    df_results.to_csv(csv_filename, index=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Grid search completed!\")\n",
    "    print(f\"Results saved to: {csv_filename}\")\n",
    "    print(f\"Total experiments: {len(all_results)}\")\n",
    "\n",
    "    return df_results\n",
    "\n",
    "\n",
    "grid_search_minibatch(datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
