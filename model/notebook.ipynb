{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42b5a73",
   "metadata": {},
   "source": [
    "# 🤖 Multilayer Perceptron\n",
    "\n",
    "Esta Jupyter Notebook implementa una MLP para detectar patrones en una matriz 10x10.\n",
    "Se genera un dataset para luego entrenar el modelo y validarlo.\n",
    "Se evalúa la precisión para reiterar sobre el modelo con el objetivo de mejorar su eficacia.\n",
    "Finalmente se exporta el modelo para ser utilizado en la aplicación web.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941e0c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 📋 Situación\n",
    "\n",
    "En una matriz 10x10 se debe poder detectar las letras `b`, `d`, `f` que se corresponden a los siguientes patrones:\n",
    "\n",
    "![Patrones que el MLP deberá reconocer](assets/patterns.png)\n",
    "\n",
    "Ante un dato nuevo, el MLP deberá ser capaz de clasificar el contenido de esa matriz en uno de los tres patrones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c64b1e6",
   "metadata": {},
   "source": [
    "## 🗃️ Generación de Datasets\n",
    "\n",
    "Conviene generar el conjunto de datos de manera programática.\n",
    "Los datasets deberán ser representativos a la hora de definir la distribución de los ejemplos de entrenamiento.\n",
    "Se definen los patrones 'b', 'd', y 'f'.\n",
    "Luego, se crea una función `generate_sample` que crea un ejemplo de un patrón dado con una distorsión entre 0 y 0.3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c45330a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 'b' pattern with zero noise:\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 1 1 1 1 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 1 1 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "A 'b' with 30% noise, meaning 30 out of 100 cells have been randomly flipped:\n",
      "[[1 0 0 0 1 0 0 0 0 1]\n",
      " [1 0 1 0 0 1 0 1 1 0]\n",
      " [0 0 1 0 0 0 1 1 0 0]\n",
      " [1 1 0 1 0 0 0 1 0 1]\n",
      " [1 0 1 1 0 0 1 1 0 0]\n",
      " [0 0 1 1 0 1 0 1 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 1]\n",
      " [1 0 0 1 0 0 1 0 0 0]\n",
      " [1 0 0 0 1 1 1 1 1 0]\n",
      " [1 0 0 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "import numpy as np\n",
    "\n",
    "# Define the 10x10 patterns for 'b', 'd', and 'f'\n",
    "PATTERNS = {\n",
    "    \"b\": np.array(\n",
    "        [\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        ],\n",
    "        dtype=np.uint8,\n",
    "    ),\n",
    "    \"d\": np.array(\n",
    "        [\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 0, 1, 1, 1, 1, 1, 0, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 0, 1, 1, 1, 1, 1, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        ],\n",
    "        dtype=np.uint8,\n",
    "    ),\n",
    "    \"f\": np.array(\n",
    "        [\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        ],\n",
    "        dtype=np.uint8,\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def generate_sample(\n",
    "    pattern: Literal[\"b\", \"d\", \"f\"], noise: float = 0.0\n",
    ") -> np.ndarray[np.ndarray[int]]:\n",
    "    \"\"\"\n",
    "    Generates a 10x10 matrix based on a given pattern letter ('b', 'd', or 'f'), with optional noise.\n",
    "    Args:\n",
    "        pattern: One of 'b', 'd', or 'f'.\n",
    "        noise: Proportion of pixels to flip.\n",
    "    Returns:\n",
    "        A 10x10 numpy array with the pattern and noise applied.\n",
    "    \"\"\"\n",
    "    matrix = PATTERNS[pattern].copy()\n",
    "    num_pixels = matrix.size\n",
    "    num_noisy = int(noise * num_pixels)\n",
    "\n",
    "    if num_noisy > 0:\n",
    "        # Choose random indices to flip\n",
    "        indices = np.unravel_index(\n",
    "            np.random.choice(num_pixels, num_noisy, replace=False), matrix.shape\n",
    "        )\n",
    "        # Flip the selected pixels (0 becomes 1, 1 becomes 0)\n",
    "        matrix[indices] = 1 - matrix[indices]\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "print(\"A 'b' pattern with zero noise:\")\n",
    "print(generate_sample(\"d\", 0.00))\n",
    "print()\n",
    "print(\"A 'b' with 30% noise, meaning 30 out of 100 cells have been randomly flipped:\")\n",
    "print(generate_sample(\"d\", 0.30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a38b2bb",
   "metadata": {},
   "source": [
    "Luego se generan 3 datasets que contengan 100, 500 y 1000 ejemplos. \n",
    "El 10% serán patrones sin distorsionar y el resto con una distorsión del 1% al 30%.\n",
    "Se usará una **distribución uniforme** para ubicar el 90% de ejemplos en el rango de distorsión entre 0.01 y 0.30.\n",
    "\n",
    "Cada dataset será un `pd.DataFrame` de `pandas` que contiene columnas del `0` al `99` (una por cada celda de la matriz) y una columna final `class` que indica la clase del patrón ('b', 'd' o 'f').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b187c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset de 1000 ejemplos es el siguiente:\n",
      "     0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "1    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "2    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "3    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "4    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "..  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "995  0  0  0  0  0  0  1  0  1  1  ...   0   1   0   0   0   1   0   0   1      f\n",
      "996  0  0  0  1  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   1      f\n",
      "997  0  0  1  0  1  1  0  0  0  0  ...   0   1   0   0   0   0   0   0   0      b\n",
      "998  0  0  0  1  0  0  0  0  1  1  ...   0   0   0   0   0   0   0   0   1      d\n",
      "999  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "\n",
      "[1000 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extend maximum width when printing DataFrames so they fit in just one line\n",
    "pd.options.display.width = 100\n",
    "\n",
    "\n",
    "def generate_dataset(n_samples: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a dataset of pattern samples.\n",
    "    The 90% of samples will have noise between 0.01 and 0.30.\n",
    "\n",
    "    Args:\n",
    "        n_samples: Number of samples to generate.\n",
    "    Returns:\n",
    "        A dataframe with 100 columns for the flattened pattern and 1 column 'class' for the pattern class.\n",
    "    \"\"\"\n",
    "    columns = [str(i) for i in range(100)] + [\"class\"]\n",
    "    df = pd.DataFrame(0, index=np.arange(n_samples), columns=columns)\n",
    "    df = df.astype({\"class\": \"str\"})\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # 10% without distortion, 90% with distortion between 1% and 30%\n",
    "        if i < int(0.1 * n_samples):\n",
    "            noise = 0.0\n",
    "        else:\n",
    "            noise = np.random.uniform(0.01, 0.30)\n",
    "\n",
    "        # Pick a pattern at random\n",
    "        pattern = np.random.choice(list(PATTERNS.keys()))\n",
    "\n",
    "        sample = generate_sample(pattern, noise).flatten()\n",
    "        df.iloc[i, :100] = sample\n",
    "        df.loc[i, \"class\"] = pattern\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_100 = generate_dataset(100)\n",
    "df_500 = generate_dataset(500)\n",
    "df_1000 = generate_dataset(1000)\n",
    "\n",
    "print(\"El dataset de 1000 ejemplos es el siguiente:\")\n",
    "print(df_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4837b",
   "metadata": {},
   "source": [
    "Por cada dataset deberán construirse tres conjuntos de validación con 10%, 20% y 30% de los ejemplos.\n",
    "Esto da un total de 9 pares de datasets de entrenamiento y datasets de validación:\n",
    "\n",
    "1. Dataset original de 100 ejemplos con 90% para entrenamiento y 10% para validación.\n",
    "2. Dataset original de 100 ejemplos con 80% para entrenamiento y 20% para validación.\n",
    "3. Dataset original de 100 ejemplos con 70% para entrenamiento y 30% para validación.\n",
    "4. Dataset original de 500 ejemplos con 90% para entrenamiento y 10% para validación.\n",
    "5. Dataset original de 500 ejemplos con 80% para entrenamiento y 20% para validación.\n",
    "6. Dataset original de 500 ejemplos con 70% para entrenamiento y 30% para validación.\n",
    "7. Dataset original de 1000 ejemplos con 90% para entrenamiento y 10% para validación.\n",
    "8. Dataset original de 1000 ejemplos con 80% para entrenamiento y 20% para validación.\n",
    "9. Dataset original de 1000 ejemplos con 70% para entrenamiento y 30% para validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "778a91fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'100': {'val_10%': {'training':     0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0   0  0  0  0  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "1   0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "2   0  0  0  0  0  0  1  0  0  1  ...   0   0   1   0   0   0   1   0   0      f\n",
      "3   0  0  1  0  0  1  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "4   0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      ".. .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "85  0  0  0  0  0  0  1  1  0  0  ...   0   0   0   1   0   1   0   1   1      d\n",
      "86  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   1   0   0      b\n",
      "87  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "88  0  0  0  0  0  0  0  0  0  0  ...   1   0   1   0   0   1   0   0   0      b\n",
      "89  0  0  0  0  1  0  0  1  0  0  ...   1   0   0   0   0   0   0   0   0      b\n",
      "\n",
      "[90 rows x 101 columns], 'validation':    0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0  0  0  0  0  0  0  0  1  0  0  ...   1   0   1   0   1   1   0   0   0      f\n",
      "1  0  0  0  1  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "2  1  0  1  1  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   0   1      f\n",
      "3  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   1   0   0   0   0   0      b\n",
      "4  0  0  0  0  1  0  0  0  0  0  ...   0   1   0   0   0   0   0   0   1      d\n",
      "5  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "6  0  0  0  1  0  0  1  1  0  0  ...   0   0   0   1   1   1   0   0   0      f\n",
      "7  0  0  1  0  0  1  0  0  0  0  ...   0   0   0   0   0   0   0   0   1      f\n",
      "8  0  0  0  0  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   0   1      f\n",
      "9  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "\n",
      "[10 rows x 101 columns]}, 'val_20%': {'training':     0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0   0  0  0  0  0  0  0  0  1  0  ...   1   0   0   0   0   0   0   1   0      f\n",
      "1   0  0  0  0  0  0  0  0  0  0  ...   0   0   1   0   0   0   1   0   0      d\n",
      "2   0  0  0  1  1  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "3   0  0  0  0  0  0  0  0  0  1  ...   1   0   0   0   0   0   0   0   0      f\n",
      "4   0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   1   0   0      d\n",
      ".. .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "75  0  0  0  0  0  0  1  1  0  0  ...   0   0   0   1   0   1   0   1   1      d\n",
      "76  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   1   0   0      b\n",
      "77  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "78  0  0  0  0  0  0  0  0  0  0  ...   1   0   1   0   0   1   0   0   0      b\n",
      "79  0  0  0  0  1  0  0  1  0  0  ...   1   0   0   0   0   0   0   0   0      b\n",
      "\n",
      "[80 rows x 101 columns], 'validation':     0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0   0  0  0  0  0  0  0  1  0  0  ...   1   0   1   0   1   1   0   0   0      f\n",
      "1   0  0  0  1  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "2   1  0  1  1  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   0   1      f\n",
      "3   0  0  0  0  0  0  0  0  0  0  ...   0   0   0   1   0   0   0   0   0      b\n",
      "4   0  0  0  0  1  0  0  0  0  0  ...   0   1   0   0   0   0   0   0   1      d\n",
      "5   0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "6   0  0  0  1  0  0  1  1  0  0  ...   0   0   0   1   1   1   0   0   0      f\n",
      "7   0  0  1  0  0  1  0  0  0  0  ...   0   0   0   0   0   0   0   0   1      f\n",
      "8   0  0  0  0  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   0   1      f\n",
      "9   0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "10  0  0  0  0  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "11  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "12  0  0  0  0  0  0  1  0  0  1  ...   0   0   1   0   0   0   1   0   0      f\n",
      "13  0  0  1  0  0  1  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "14  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "15  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "16  0  0  0  0  1  0  0  0  0  1  ...   1   0   0   0   0   0   0   1   0      f\n",
      "17  1  0  0  1  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "18  0  0  1  0  1  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   1      d\n",
      "19  0  0  0  1  0  0  0  0  1  1  ...   0   1   0   0   0   0   0   0   0      b\n",
      "\n",
      "[20 rows x 101 columns]}, 'val_30%': {'training':     0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0   0  0  0  0  0  1  0  0  0  1  ...   0   0   1   1   1   0   1   0   0      d\n",
      "1   1  0  0  0  0  0  1  0  1  1  ...   0   0   0   0   1   1   0   0   0      f\n",
      "2   0  0  0  0  0  0  0  1  0  0  ...   0   0   0   1   0   0   0   0   0      f\n",
      "3   0  0  1  1  0  0  1  0  0  0  ...   0   0   1   1   0   0   0   0   0      f\n",
      "4   0  0  0  0  0  1  1  0  0  0  ...   0   0   1   1   1   0   0   0   0      d\n",
      ".. .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "65  0  0  0  0  0  0  1  1  0  0  ...   0   0   0   1   0   1   0   1   1      d\n",
      "66  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   1   0   0      b\n",
      "67  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "68  0  0  0  0  0  0  0  0  0  0  ...   1   0   1   0   0   1   0   0   0      b\n",
      "69  0  0  0  0  1  0  0  1  0  0  ...   1   0   0   0   0   0   0   0   0      b\n",
      "\n",
      "[70 rows x 101 columns], 'validation':     0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0   0  0  0  0  0  0  0  1  0  0  ...   1   0   1   0   1   1   0   0   0      f\n",
      "1   0  0  0  1  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "2   1  0  1  1  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   0   1      f\n",
      "3   0  0  0  0  0  0  0  0  0  0  ...   0   0   0   1   0   0   0   0   0      b\n",
      "4   0  0  0  0  1  0  0  0  0  0  ...   0   1   0   0   0   0   0   0   1      d\n",
      "5   0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "6   0  0  0  1  0  0  1  1  0  0  ...   0   0   0   1   1   1   0   0   0      f\n",
      "7   0  0  1  0  0  1  0  0  0  0  ...   0   0   0   0   0   0   0   0   1      f\n",
      "8   0  0  0  0  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   0   1      f\n",
      "9   0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "10  0  0  0  0  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "11  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "12  0  0  0  0  0  0  1  0  0  1  ...   0   0   1   0   0   0   1   0   0      f\n",
      "13  0  0  1  0  0  1  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "14  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "15  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "16  0  0  0  0  1  0  0  0  0  1  ...   1   0   0   0   0   0   0   1   0      f\n",
      "17  1  0  0  1  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "18  0  0  1  0  1  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   1      d\n",
      "19  0  0  0  1  0  0  0  0  1  1  ...   0   1   0   0   0   0   0   0   0      b\n",
      "20  0  0  0  0  0  0  0  0  1  0  ...   1   0   0   0   0   0   0   1   0      f\n",
      "21  0  0  0  0  0  0  0  0  0  0  ...   0   0   1   0   0   0   1   0   0      d\n",
      "22  0  0  0  1  1  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "23  0  0  0  0  0  0  0  0  0  1  ...   1   0   0   0   0   0   0   0   0      f\n",
      "24  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   1   0   0      d\n",
      "25  0  0  0  1  0  0  1  0  0  0  ...   0   0   0   1   1   0   0   0   1      b\n",
      "26  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "27  0  0  1  0  1  0  0  0  0  0  ...   0   0   0   0   0   0   1   0   0      b\n",
      "28  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "29  0  1  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   1   0   0      b\n",
      "\n",
      "[30 rows x 101 columns]}}, '500': {'val_10%': {'training':      0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0    0  0  0  0  1  0  0  0  0  0  ...   1   1   0   0   0   0   1   0   0      d\n",
      "1    0  0  0  0  0  0  0  0  0  0  ...   0   0   1   0   0   0   1   0   0      b\n",
      "2    0  0  0  0  0  1  0  1  1  1  ...   0   0   0   0   0   0   0   0   0      d\n",
      "3    0  1  0  1  0  0  0  0  0  0  ...   0   1   0   0   0   0   1   0   0      b\n",
      "4    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   1   0   0   0   0   0      d\n",
      "..  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "445  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   1   0   0   0      b\n",
      "446  0  0  1  1  0  1  1  0  1  0  ...   0   0   1   0   0   0   0   1   0      b\n",
      "447  0  0  1  0  0  0  0  0  0  0  ...   0   0   0   0   1   0   0   0   0      b\n",
      "448  0  0  0  0  0  0  0  1  0  0  ...   0   0   0   1   0   0   0   1   1      b\n",
      "449  0  0  0  0  0  0  0  0  0  0  ...   1   0   0   0   0   0   0   1   0      d\n",
      "\n",
      "[450 rows x 101 columns], 'validation':     0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0   0  0  0  0  1  0  0  1  0  0  ...   0   0   0   0   0   0   1   0   0      b\n",
      "1   0  0  0  0  0  0  0  0  0  0  ...   1   1   0   0   1   0   1   0   0      f\n",
      "2   0  0  0  0  0  0  0  1  1  0  ...   1   1   1   0   0   0   0   0   1      f\n",
      "3   0  0  0  0  1  0  0  0  0  0  ...   1   1   0   0   0   0   0   0   0      b\n",
      "4   0  0  0  0  0  0  1  0  0  1  ...   0   0   0   0   0   0   0   0   0      f\n",
      "5   0  1  0  0  0  0  0  0  0  0  ...   0   1   0   0   0   0   0   0   0      b\n",
      "6   1  0  0  1  1  0  1  1  0  0  ...   0   1   0   0   0   1   0   0   0      d\n",
      "7   0  0  0  0  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   0   0      f\n",
      "8   0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   1   0   0   0   0      d\n",
      "9   0  0  0  1  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "10  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "11  1  0  0  1  0  0  0  0  0  0  ...   0   0   0   1   0   0   0   0   1      b\n",
      "12  0  0  0  0  0  0  0  1  0  0  ...   0   0   1   0   0   0   0   0   0      d\n",
      "13  0  0  0  0  0  0  1  0  1  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "14  0  1  0  0  0  0  0  0  0  0  ...   1   0   0   0   0   1   0   0   1      d\n",
      "15  0  0  1  0  0  1  1  1  0  0  ...   0   0   0   0   0   1   0   0   0      d\n",
      "16  0  0  0  0  0  1  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "17  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "18  0  0  0  1  0  1  1  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "19  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "20  0  0  0  0  0  1  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "21  0  0  0  1  0  0  0  0  0  0  ...   0   1   0   1   0   1   0   0   0      b\n",
      "22  0  0  0  0  1  0  1  1  0  1  ...   1   0   0   0   0   0   1   0   1      b\n",
      "23  0  0  0  0  0  0  0  0  0  0  ...   0   0   1   1   0   0   0   1   0      b\n",
      "24  1  0  0  0  0  0  0  0  0  1  ...   1   0   0   0   1   0   0   0   0      b\n",
      "25  1  0  0  0  0  1  0  0  0  1  ...   0   0   0   0   1   1   0   0   1      d\n",
      "26  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "27  1  0  1  1  0  0  0  0  0  0  ...   1   0   0   0   0   0   0   0   0      b\n",
      "28  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "29  0  0  0  0  0  0  0  0  0  0  ...   0   0   1   1   0   0   0   0   0      b\n",
      "30  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   1   0   0   0      b\n",
      "31  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   1   0   0   0      b\n",
      "32  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "33  0  0  0  0  0  0  0  1  0  0  ...   1   0   0   0   0   1   0   0   0      f\n",
      "34  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "35  1  0  0  0  0  1  1  0  0  0  ...   0   0   0   1   0   1   0   0   0      b\n",
      "36  0  0  0  0  0  1  0  0  1  0  ...   0   0   0   1   0   0   0   0   1      f\n",
      "37  1  0  0  0  0  0  1  1  0  0  ...   0   0   0   0   0   0   0   0   1      d\n",
      "38  0  1  0  0  0  0  1  0  0  1  ...   0   0   0   0   0   0   1   0   0      d\n",
      "39  0  1  0  1  0  0  0  0  0  1  ...   0   0   0   0   0   0   1   0   0      d\n",
      "40  0  0  0  0  1  0  0  0  1  0  ...   0   0   1   0   0   0   0   0   0      b\n",
      "41  0  0  0  0  0  0  0  0  0  0  ...   1   0   0   1   0   0   0   1   0      f\n",
      "42  0  0  0  0  0  0  0  0  0  0  ...   1   0   0   0   0   0   0   0   0      f\n",
      "43  0  1  0  1  0  0  0  1  0  0  ...   0   1   0   0   0   0   0   1   0      d\n",
      "44  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "45  0  0  0  0  0  1  1  0  0  0  ...   1   1   0   0   1   0   0   0   0      b\n",
      "46  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "47  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "48  1  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "49  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "\n",
      "[50 rows x 101 columns]}, 'val_20%': {'training':      0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0    1  0  0  0  0  0  0  0  0  1  ...   0   0   1   0   0   0   1   0   0      f\n",
      "1    1  0  1  0  0  1  0  0  0  0  ...   0   0   1   1   0   1   0   0   0      b\n",
      "2    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "3    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "4    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   1   0   0   0   0   0      b\n",
      "..  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "395  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   1   0   0   0      b\n",
      "396  0  0  1  1  0  1  1  0  1  0  ...   0   0   1   0   0   0   0   1   0      b\n",
      "397  0  0  1  0  0  0  0  0  0  0  ...   0   0   0   0   1   0   0   0   0      b\n",
      "398  0  0  0  0  0  0  0  1  0  0  ...   0   0   0   1   0   0   0   1   1      b\n",
      "399  0  0  0  0  0  0  0  0  0  0  ...   1   0   0   0   0   0   0   1   0      d\n",
      "\n",
      "[400 rows x 101 columns], 'validation':     0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0   0  0  0  0  1  0  0  1  0  0  ...   0   0   0   0   0   0   1   0   0      b\n",
      "1   0  0  0  0  0  0  0  0  0  0  ...   1   1   0   0   1   0   1   0   0      f\n",
      "2   0  0  0  0  0  0  0  1  1  0  ...   1   1   1   0   0   0   0   0   1      f\n",
      "3   0  0  0  0  1  0  0  0  0  0  ...   1   1   0   0   0   0   0   0   0      b\n",
      "4   0  0  0  0  0  0  1  0  0  1  ...   0   0   0   0   0   0   0   0   0      f\n",
      ".. .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "95  0  0  0  0  0  0  0  1  0  0  ...   0   0   1   0   0   0   0   0   1      b\n",
      "96  1  1  0  0  0  0  0  0  0  0  ...   0   0   0   1   0   0   1   0   0      b\n",
      "97  0  1  0  0  1  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "98  1  1  0  0  0  0  0  0  1  0  ...   0   1   1   0   0   0   1   0   0      f\n",
      "99  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "\n",
      "[100 rows x 101 columns]}, 'val_30%': {'training':      0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "1    0  0  0  0  0  0  0  1  0  0  ...   1   0   1   0   0   1   0   1   0      b\n",
      "2    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "3    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "4    0  0  1  0  0  0  0  0  1  1  ...   1   0   0   0   0   1   0   0   0      f\n",
      "..  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "345  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   1   0   0   0      b\n",
      "346  0  0  1  1  0  1  1  0  1  0  ...   0   0   1   0   0   0   0   1   0      b\n",
      "347  0  0  1  0  0  0  0  0  0  0  ...   0   0   0   0   1   0   0   0   0      b\n",
      "348  0  0  0  0  0  0  0  1  0  0  ...   0   0   0   1   0   0   0   1   1      b\n",
      "349  0  0  0  0  0  0  0  0  0  0  ...   1   0   0   0   0   0   0   1   0      d\n",
      "\n",
      "[350 rows x 101 columns], 'validation':      0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0    0  0  0  0  1  0  0  1  0  0  ...   0   0   0   0   0   0   1   0   0      b\n",
      "1    0  0  0  0  0  0  0  0  0  0  ...   1   1   0   0   1   0   1   0   0      f\n",
      "2    0  0  0  0  0  0  0  1  1  0  ...   1   1   1   0   0   0   0   0   1      f\n",
      "3    0  0  0  0  1  0  0  0  0  0  ...   1   1   0   0   0   0   0   0   0      b\n",
      "4    0  0  0  0  0  0  1  0  0  1  ...   0   0   0   0   0   0   0   0   0      f\n",
      "..  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "145  0  1  0  0  0  0  1  0  0  1  ...   1   0   0   0   1   0   0   0   0      d\n",
      "146  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "147  0  0  0  0  1  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "148  0  0  1  0  0  0  0  1  0  1  ...   0   0   0   0   0   0   1   0   0      b\n",
      "149  0  1  0  0  0  0  1  0  1  0  ...   0   0   0   0   0   0   0   0   1      f\n",
      "\n",
      "[150 rows x 101 columns]}}, '1000': {'val_10%': {'training':      0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "1    0  0  0  0  1  0  0  1  1  0  ...   1   0   0   0   1   1   0   0   0      b\n",
      "2    0  1  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "3    1  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "4    1  0  0  1  1  0  1  0  1  0  ...   0   0   0   0   0   0   0   1   1      d\n",
      "..  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "895  0  0  0  0  0  0  0  0  0  0  ...   0   0   1   1   0   0   0   0   0      d\n",
      "896  1  0  0  1  0  0  0  0  0  1  ...   0   0   0   0   1   1   0   0   0      d\n",
      "897  0  0  1  0  0  0  0  0  0  0  ...   1   0   0   0   0   0   0   0   0      b\n",
      "898  0  0  0  0  0  0  0  0  1  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "899  1  0  0  0  0  0  1  1  0  0  ...   1   0   0   0   0   1   0   0   0      f\n",
      "\n",
      "[900 rows x 101 columns], 'validation':     0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0   0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "1   0  0  1  0  0  0  0  0  0  0  ...   0   0   1   0   0   1   0   0   0      b\n",
      "2   0  0  0  1  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "3   0  0  1  0  0  0  0  1  0  0  ...   0   0   0   0   0   0   0   1   0      d\n",
      "4   0  0  1  0  0  0  0  1  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      ".. .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "95  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   1   0   0   0      b\n",
      "96  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   1   1   0      d\n",
      "97  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "98  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "99  1  0  0  0  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   0   1      f\n",
      "\n",
      "[100 rows x 101 columns]}, 'val_20%': {'training':      0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "1    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "2    1  0  0  1  0  0  0  0  0  0  ...   0   1   0   0   1   0   0   0   0      f\n",
      "3    0  0  1  0  1  0  0  1  0  0  ...   0   0   0   1   0   0   0   0   1      b\n",
      "4    0  1  1  1  0  0  1  0  0  0  ...   0   0   0   0   1   1   0   0   0      f\n",
      "..  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "795  0  0  0  0  0  0  0  0  0  0  ...   0   0   1   1   0   0   0   0   0      d\n",
      "796  1  0  0  1  0  0  0  0  0  1  ...   0   0   0   0   1   1   0   0   0      d\n",
      "797  0  0  1  0  0  0  0  0  0  0  ...   1   0   0   0   0   0   0   0   0      b\n",
      "798  0  0  0  0  0  0  0  0  1  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "799  1  0  0  0  0  0  1  1  0  0  ...   1   0   0   0   0   1   0   0   0      f\n",
      "\n",
      "[800 rows x 101 columns], 'validation':      0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "1    0  0  1  0  0  0  0  0  0  0  ...   0   0   1   0   0   1   0   0   0      b\n",
      "2    0  0  0  1  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "3    0  0  1  0  0  0  0  1  0  0  ...   0   0   0   0   0   0   0   1   0      d\n",
      "4    0  0  1  0  0  0  0  1  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "..  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "195  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "196  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   1   0      f\n",
      "197  0  1  0  0  0  0  0  0  0  0  ...   0   1   0   0   0   0   0   0   0      f\n",
      "198  0  0  0  1  0  0  0  1  0  0  ...   0   0   0   1   0   0   0   0   0      f\n",
      "199  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "\n",
      "[200 rows x 101 columns]}, 'val_30%': {'training':      0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   1   0   1   0   0   0      d\n",
      "1    0  0  0  0  0  1  1  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "2    1  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "3    0  0  0  1  1  0  0  0  0  0  ...   1   0   1   0   1   1   0   0   1      b\n",
      "4    0  0  0  0  0  0  0  0  0  0  ...   0   1   1   0   0   0   0   0   0      d\n",
      "..  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "695  0  0  0  0  0  0  0  0  0  0  ...   0   0   1   1   0   0   0   0   0      d\n",
      "696  1  0  0  1  0  0  0  0  0  1  ...   0   0   0   0   1   1   0   0   0      d\n",
      "697  0  0  1  0  0  0  0  0  0  0  ...   1   0   0   0   0   0   0   0   0      b\n",
      "698  0  0  0  0  0  0  0  0  1  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "699  1  0  0  0  0  0  1  1  0  0  ...   1   0   0   0   0   1   0   0   0      f\n",
      "\n",
      "[700 rows x 101 columns], 'validation':      0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "1    0  0  1  0  0  0  0  0  0  0  ...   0   0   1   0   0   1   0   0   0      b\n",
      "2    0  0  0  1  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "3    0  0  1  0  0  0  0  1  0  0  ...   0   0   0   0   0   0   0   1   0      d\n",
      "4    0  0  1  0  0  0  0  1  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "..  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "295  0  0  1  0  0  0  1  0  0  1  ...   0   1   0   0   0   0   0   0   0      f\n",
      "296  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   1      b\n",
      "297  1  1  0  0  1  0  0  0  0  1  ...   1   1   0   0   1   0   0   0   1      f\n",
      "298  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "299  0  0  0  1  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "\n",
      "[300 rows x 101 columns]}}}\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_RATIOS = [0.1, 0.2, 0.3]\n",
    "\n",
    "\n",
    "def split_dataset(df: pd.DataFrame, validation_ratio: float, random_state: int = None):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and validation sets.\n",
    "\n",
    "    Args:\n",
    "        df: The dataset to split.\n",
    "        validation_ratio: Proportion (between 0 and 1) of the dataset to include in the validation set.\n",
    "        random_state (optional): Seed for reproducibility.\n",
    "    Returns:\n",
    "        tuple: (training_df, validation_df)\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    shuffled_df = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    validation_size = int(len(df) * validation_ratio)\n",
    "    validation_df = shuffled_df.iloc[:validation_size].reset_index(drop=True)\n",
    "    training_df = shuffled_df.iloc[validation_size:].reset_index(drop=True)\n",
    "    return training_df, validation_df\n",
    "\n",
    "\n",
    "# Store all datasets in one dictionary\n",
    "datasets = {}\n",
    "for df_name, df in [(\"100\", df_100), (\"500\", df_500), (\"1000\", df_1000)]:\n",
    "    datasets[df_name] = {}\n",
    "    for validation_ratio in VALIDATION_RATIOS:\n",
    "        training, validation = split_dataset(df, validation_ratio, random_state=42)\n",
    "        key = f\"val_{int(validation_ratio * 100)}%\"\n",
    "        # Store training dataset and validation dataset for each dataset, for each validation split\n",
    "        datasets[df_name][key] = {\n",
    "            \"training\": training,\n",
    "            \"validation\": validation,\n",
    "        }\n",
    "\n",
    "print(datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
