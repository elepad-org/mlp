{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42b5a73",
   "metadata": {},
   "source": [
    "# ü§ñ Multilayer Perceptron\n",
    "\n",
    "Esta Jupyter Notebook implementa una MLP para detectar patrones en una matriz 10x10.\n",
    "Se genera un dataset para luego entrenar el modelo y validarlo.\n",
    "Se eval√∫a la precisi√≥n para reiterar sobre el modelo con el objetivo de mejorar su eficacia.\n",
    "Finalmente se exporta el modelo para ser utilizado en la aplicaci√≥n web.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941e0c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## üìã Situaci√≥n\n",
    "\n",
    "En una matriz 10x10 se debe poder detectar las letras `b`, `d`, `f` que se corresponden a los siguientes patrones:\n",
    "\n",
    "![Patrones que el MLP deber√° reconocer](assets/patterns.png)\n",
    "\n",
    "Ante un dato nuevo, el MLP deber√° ser capaz de clasificar el contenido de esa matriz en uno de los tres patrones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70cf6248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Literal, List\n",
    "\n",
    "# Extend maximum width when printing DataFrames so they fit in just one line\n",
    "pd.options.display.width = 100\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 7\n",
    "RNG = np.random.default_rng(SEED)\n",
    "\n",
    "# fmt: off\n",
    "# Define the 10x10 patterns for 'b', 'd', and 'f' as a 1D array\n",
    "PATTERNS = {\n",
    "    \"b\": np.array(\n",
    "           [\n",
    "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "            0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "            0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "            0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "            0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "            0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
    "            0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
    "            0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
    "            0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        ],\n",
    "        dtype=np.uint8,\n",
    "    ),\n",
    "    \"d\": np.array(\n",
    "        [\n",
    "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "            0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    "            0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    "            0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    "            0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
    "            0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
    "            0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
    "            0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
    "            0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
    "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        ],\n",
    "        dtype=np.uint8,\n",
    "    ),\n",
    "    \"f\": np.array(\n",
    "        [\n",
    "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "            0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
    "            0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
    "            0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "            0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "            0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "            0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "            0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "            0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        ],\n",
    "        dtype=np.uint8,\n",
    "    ),\n",
    "}\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c64b1e6",
   "metadata": {},
   "source": [
    "## üóÉÔ∏è Generaci√≥n de Datasets\n",
    "\n",
    "Conviene generar el conjunto de datos de manera program√°tica.\n",
    "Los datasets deber√°n ser representativos a la hora de definir la distribuci√≥n de los ejemplos de entrenamiento.\n",
    "Se definen los patrones 'b', 'd', y 'f'.\n",
    "Luego, se crea una funci√≥n `generate_sample` que crea un ejemplo de un patr√≥n dado con una distorsi√≥n entre 0 y 0.3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45330a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 'b' pattern with zero noise:\n",
      "0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 \u001b[1;92m1\u001b[0m 0 0\n",
      "0 0 0 0 0 0 0 \u001b[1;92m1\u001b[0m 0 0\n",
      "0 0 0 0 0 0 0 \u001b[1;92m1\u001b[0m 0 0\n",
      "0 0 0 \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m 0 0\n",
      "0 0 \u001b[1;92m1\u001b[0m 0 0 0 0 \u001b[1;92m1\u001b[0m 0 0\n",
      "0 0 \u001b[1;92m1\u001b[0m 0 0 0 0 \u001b[1;92m1\u001b[0m 0 0\n",
      "0 0 \u001b[1;92m1\u001b[0m 0 0 0 0 \u001b[1;92m1\u001b[0m 0 0\n",
      "0 0 0 \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m 0 0\n",
      "0 0 0 0 0 0 0 0 0 0\n",
      "\n",
      "A 'b' with 30% noise, meaning 30 out of 100 cells have been randomly flipped:\n",
      "\u001b[1;92m1\u001b[0m 0 0 0 \u001b[1;92m1\u001b[0m 0 0 0 0 0\n",
      "\u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m 0 0 0 0 0 0 0 0\n",
      "0 0 0 \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m 0 \u001b[1;92m1\u001b[0m 0 0 0\n",
      "0 \u001b[1;92m1\u001b[0m 0 0 0 0 0 \u001b[1;92m1\u001b[0m 0 0\n",
      "0 0 \u001b[1;92m1\u001b[0m 0 \u001b[1;92m1\u001b[0m 0 \u001b[1;92m1\u001b[0m 0 0 \u001b[1;92m1\u001b[0m\n",
      "\u001b[1;92m1\u001b[0m 0 \u001b[1;92m1\u001b[0m 0 0 0 0 \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m 0\n",
      "0 0 \u001b[1;92m1\u001b[0m 0 \u001b[1;92m1\u001b[0m 0 \u001b[1;92m1\u001b[0m 0 \u001b[1;92m1\u001b[0m 0\n",
      "\u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m 0 \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m 0 \u001b[1;92m1\u001b[0m 0 0\n",
      "0 0 0 \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m 0 0 \u001b[1;92m1\u001b[0m\n",
      "0 0 0 0 0 \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m 0 0\n"
     ]
    }
   ],
   "source": [
    "def generate_sample(pattern: Literal[\"b\", \"d\", \"f\"], noise: float = 0.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a 1D array based on a given pattern letter ('b', 'd', or 'f'), with optional noise.\n",
    "\n",
    "    Args:\n",
    "        pattern: One of 'b', 'd', or 'f'.\n",
    "        noise: Proportion of pixels to flip.\n",
    "    Returns:\n",
    "        A numpy 1D array representing the 10x10 matrix with the pattern and noise applied.\n",
    "    \"\"\"\n",
    "    sample = PATTERNS[pattern].copy()\n",
    "    num_pixels = sample.size\n",
    "    num_noisy = int(noise * num_pixels)\n",
    "\n",
    "    if num_noisy > 0:\n",
    "        # Choose random indices to flip\n",
    "        indices = RNG.choice(num_pixels, num_noisy, replace=False)\n",
    "        # Flip the selected pixels (0 becomes 1, 1 becomes 0)\n",
    "        sample[indices] = 1 - sample[indices]\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "def print_sample(sample: np.ndarray):\n",
    "    \"\"\"\n",
    "    Pretty-prints the provided 1D array as a 10x10 matrix,\n",
    "    coloring filled pixels bold green and adding an outline to the matrix.\n",
    "\n",
    "    Args:\n",
    "        sample: 1D numpy array of 0s and 1s.\n",
    "    \"\"\"\n",
    "    BOLD_GREEN = \"\\033[1;92m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "    for i in range(10):\n",
    "        row = sample[i * 10 : (i + 1) * 10]\n",
    "        print(\" \".join([f\"{BOLD_GREEN}1{RESET}\" if val else \"0\" for val in row]))\n",
    "\n",
    "\n",
    "print(\"A 'b' pattern with zero noise:\")\n",
    "print_sample(generate_sample(\"d\", 0.00))\n",
    "print()\n",
    "print(\"A 'b' with 30% noise, meaning 30 out of 100 cells have been randomly flipped:\")\n",
    "print_sample(generate_sample(\"d\", 0.30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a38b2bb",
   "metadata": {},
   "source": [
    "Luego se generan 3 datasets que contengan 100, 500 y 1000 ejemplos. \n",
    "El 10% ser√°n patrones sin distorsionar y el resto con una distorsi√≥n del 1% al 30%.\n",
    "Se usar√° una **distribuci√≥n uniforme** para ubicar el 90% de ejemplos en el rango de distorsi√≥n entre 0.01 y 0.30.\n",
    "\n",
    "Cada dataset ser√° un `pd.DataFrame` de `pandas` que contiene columnas del `0` al `99` (una por cada celda de la matriz) y una columna final `class` que indica la clase del patr√≥n ('b', 'd' o 'f').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b187c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de 1000 ejemplos:\n",
      "     0  1  2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  class\n",
      "0    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      d\n",
      "1    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "2    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      f\n",
      "3    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "4    0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "..  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
      "995  0  0  0  1  0  1  0  0  0  0  ...   0   0   0   0   0   1   0   0   0      b\n",
      "996  0  0  0  1  0  0  0  0  0  0  ...   0   0   0   0   0   0   1   0   1      f\n",
      "997  0  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "998  0  1  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0      b\n",
      "999  1  0  0  0  0  1  1  0  0  1  ...   0   1   0   0   0   1   1   1   1      d\n",
      "\n",
      "[1000 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "def generate_dataset(n_samples: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a dataset of pattern samples.\n",
    "    The 90% of samples will have noise between 0.01 and 0.30.\n",
    "\n",
    "    Args:\n",
    "        n_samples: Number of samples to generate.\n",
    "    Returns:\n",
    "        A dataframe with 100 columns for the flattened pattern and 1 column 'class' for the pattern class.\n",
    "    \"\"\"\n",
    "    columns = [str(i) for i in range(100)] + [\"class\"]\n",
    "    df = pd.DataFrame(0, index=np.arange(n_samples), columns=columns)\n",
    "    df = df.astype({\"class\": \"str\"})\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # 10% without distortion, 90% with distortion between 1% and 30%\n",
    "        if i < int(0.1 * n_samples):\n",
    "            noise = 0.0\n",
    "        else:\n",
    "            noise = RNG.uniform(0.01, 0.30)\n",
    "\n",
    "        # Pick a pattern at random\n",
    "        pattern = RNG.choice(list(PATTERNS.keys()))\n",
    "\n",
    "        sample = generate_sample(pattern, noise).flatten()\n",
    "        df.iloc[i, :100] = sample\n",
    "        df.loc[i, \"class\"] = pattern\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_100 = generate_dataset(100)\n",
    "df_500 = generate_dataset(500)\n",
    "df_1000 = generate_dataset(1000)\n",
    "\n",
    "print(\"Dataset de 1000 ejemplos:\")\n",
    "print(df_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4837b",
   "metadata": {},
   "source": [
    "Por cada dataset deber√°n construirse tres conjuntos de validaci√≥n con 10%, 20% y 30% de los ejemplos.\n",
    "Esto da un total de 9 pares de datasets de entrenamiento y datasets de validaci√≥n:\n",
    "\n",
    "1. Dataset original de 100 ejemplos con 90% para entrenamiento y 10% para validaci√≥n.\n",
    "2. Dataset original de 100 ejemplos con 80% para entrenamiento y 20% para validaci√≥n.\n",
    "3. Dataset original de 100 ejemplos con 70% para entrenamiento y 30% para validaci√≥n.\n",
    "4. Dataset original de 500 ejemplos con 90% para entrenamiento y 10% para validaci√≥n.\n",
    "5. Dataset original de 500 ejemplos con 80% para entrenamiento y 20% para validaci√≥n.\n",
    "6. Dataset original de 500 ejemplos con 70% para entrenamiento y 30% para validaci√≥n.\n",
    "7. Dataset original de 1000 ejemplos con 90% para entrenamiento y 10% para validaci√≥n.\n",
    "8. Dataset original de 1000 ejemplos con 80% para entrenamiento y 20% para validaci√≥n.\n",
    "9. Dataset original de 1000 ejemplos con 70% para entrenamiento y 30% para validaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a91fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_RATIOS = [0.1, 0.2, 0.3]\n",
    "\n",
    "\n",
    "def split_dataset(df: pd.DataFrame, validation_ratio: float):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and validation sets.\n",
    "\n",
    "    Args:\n",
    "        df: The dataset to split.\n",
    "        validation_ratio: Proportion (between 0 and 1) of the dataset to include in the validation set.\n",
    "    Returns:\n",
    "        tuple: (training_df, validation_df).\n",
    "    \"\"\"\n",
    "    shuffled_df = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "    validation_size = int(len(df) * validation_ratio)\n",
    "    validation_df = shuffled_df.iloc[:validation_size].reset_index(drop=True)\n",
    "    training_df = shuffled_df.iloc[validation_size:].reset_index(drop=True)\n",
    "    return training_df, validation_df\n",
    "\n",
    "\n",
    "# Store all datasets in one dictionary\n",
    "datasets = {}\n",
    "for df_name, df in [(\"100\", df_100), (\"500\", df_500), (\"1000\", df_1000)]:\n",
    "    datasets[df_name] = {}\n",
    "    for validation_ratio in VALIDATION_RATIOS:\n",
    "        training, validation = split_dataset(df, validation_ratio)\n",
    "        key = f\"val_{int(validation_ratio * 100)}%\"\n",
    "        # Store training dataset and validation dataset for each dataset, for each validation split\n",
    "        datasets[df_name][key] = {\n",
    "            \"training\": training,\n",
    "            \"validation\": validation,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e003dece",
   "metadata": {},
   "source": [
    "## üß† Implementaci√≥n del Modelo\n",
    "\n",
    "Se debe implementar el algoritmo MLP que permita, dado un dataset, parametrizar la cantidad de capas, neuronas y funciones de activaci√≥n con los que se entrenar√° la red neuronal.\n",
    "\n",
    "Requerimientos para la arquitectura del modelo:\n",
    "\n",
    "- 1 o 2 capas ocultas.\n",
    "- De 5 a 10 neuronas por capa.\n",
    "- Funciones de activaci√≥n: lineal y sigmoidal.\n",
    "- Coeficiente de aprendizaje entre 0 y 1.\n",
    "- T√©rmino momento entre 0 y 1.\n",
    "\n",
    "Para estudiar el algoritmo se utiliza de referencia la bibliograf√≠a recomendada por la c√°tedra [disponible en el campus virtual](https://frre.cvg.utn.edu.ar/pluginfile.php/105673/mod_label/intro/Perceprtr%C3%B3n-MLP.pdf):\n",
    "\n",
    "- Hilera, J. R. Martinez, V. J. (2000) Redes Neuronales Artificiales. Fundamentos, modelos y aplicaciones. Alfaomega.\n",
    "\n",
    "Tambi√©n se consulta material complementario para resolver dudas durante la implementaci√≥n:\n",
    "\n",
    "- Prince, S. J. D. (2023). Understanding deep learning. The MIT Press. [http://udlbook.com](http://udlbook.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e04cb2a",
   "metadata": {},
   "source": [
    "### Arquitectura\n",
    "\n",
    "La arquitectura de esta red neuronal feedforward (MLP) consiste en:\n",
    "\n",
    "- **Capa de entrada:** 100 neuronas, una por cada celda de la matriz.\n",
    "- **Capa oculta 1:** 10 neuronas.\n",
    "- **Capa oculta 2:** 5 neuronas.\n",
    "- **Capa de salida:** 3 neuronas, una para la clasificaci√≥n de cada patr√≥n 'b', 'd', 'f'.\n",
    "\n",
    "Pr√≥ximamente los hiperpar√°metros ser√°n parametrizables, pero se utiliza esta arquitectura como base.\n",
    "\n",
    "![Diagrama de la arquitectura del MLP](assets/architecture.png)\n",
    "\n",
    "Esta red neuronal ser√° una funci√≥n $f[X, \\phi] = Y$ que clasifica el contenido de una matriz 10x10 en uno de tres patrones. \n",
    "El contenido de la matriz 10x10 se representa como el vector de entrada $X = [x_0, x_1, \\dots, x_{99}]^T$.\n",
    "El vector de salida $Y = [y_b, y_d, y_f]^T$ contiene la predicci√≥n del modelo para cada patr√≥n.\n",
    "El conjunto de par√°metros $\\phi = \\set{B_k, W_k}_{k=0}^K$ del modelo contiene:\n",
    "\n",
    "- El vector de _biases_ $B_k$ que contribuyen a la capa $k+1$. Es de tama√±o $D_{k+1}$.\n",
    "- Los _weights_ (pesos) $W_k$ que son aplicados a la capa $k$ y que contribuyen a la capa $k+1$. Es de tama√±o $D_{k+1}  \\times D_k$.\n",
    "\n",
    "La red neuronal se puede representar utilizando notaci√≥n matricial:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "X &= [x_0, x_2, \\dots, x_{99}]^T \\\\\n",
    "H_1 &= a \\left[ B_{0} + W_{0} X \\right] \\\\\n",
    "H_2 &= a \\left[ B_{1} + W_{1} H_1 \\right] \\\\\n",
    "Y &= B_2 + W_{2} H_2 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "donde $a[\\bullet]$ es una funci√≥n que aplica la funci√≥n de activaci√≥n por separado a cada elemento de su vector de entrada (Prince, 2023).\n",
    "\n",
    "Esa notaci√≥n se puede expandir de la siguiente manera:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "H_1\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "h_0 \\\\\n",
    "h_1 \\\\\n",
    "\\vdots \\\\\n",
    "h_9\n",
    "\\end{bmatrix}\n",
    "= \n",
    "a\n",
    "\\left[\n",
    "\\begin{bmatrix}\n",
    "b_{0} \\\\\n",
    "b_{1} \\\\\n",
    "\\vdots \\\\\n",
    "b_{9}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "w_{01} & w_{02} & \\dots & w_{0\\ 99} \\\\\n",
    "w_{11} & w_{12} & \\dots & w_{1\\ 99} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "w_{91} & w_{92} & \\dots & w_{9\\ 99} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_{0} \\\\\n",
    "x_{1} \\\\\n",
    "\\vdots \\\\\n",
    "x_{99}\n",
    "\\end{bmatrix}\n",
    "\\right]  \\\\\n",
    "\n",
    "H_2\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "h'_0 \\\\\n",
    "h'_1 \\\\\n",
    "\\vdots \\\\\n",
    "h'_4\n",
    "\\end{bmatrix}\n",
    "= \n",
    "a\n",
    "\\left[\n",
    "\\begin{bmatrix}\n",
    "b'_{0} \\\\\n",
    "b'_{1} \\\\\n",
    "\\vdots \\\\\n",
    "b'_{4}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "w'_{01} & w'_{02} & \\dots & w'_{09} \\\\\n",
    "w'_{11} & w'_{12} & \\dots & w'_{19} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "w'_{41} & w'_{42} & \\dots & w'_{49} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "h_{0} \\\\\n",
    "h_{1} \\\\\n",
    "\\vdots \\\\\n",
    "h_{9}\n",
    "\\end{bmatrix}\n",
    "\\right]  \\\\\n",
    "\n",
    "Y\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "y_b \\\\\n",
    "y_d \\\\\n",
    "y_f\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "b''_{0} \\\\\n",
    "b''_{1} \\\\\n",
    "b''_{2}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "w''_{01} & w''_{02} & \\dots & w''_{04} \\\\\n",
    "w''_{11} & w''_{12} & \\dots & w''_{14} \\\\\n",
    "w''_{21} & w''_{22} & \\dots & w''_{24} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "h'_{0} \\\\\n",
    "h'_{1} \\\\\n",
    "\\vdots \\\\\n",
    "h'_{4}\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Por ejemplo, la segunda neurona de la primera capa oculta se calcula como $h_1 = a[b_1 + w_{11}x_0 + \\dots + w_{1\\ 99}x_{99}]$.\n",
    "\n",
    "Los par√°metros de $\\phi$ ser√°n inicializados utilizando la t√©cnica de Xavier Glorot, y el entrenamiento del MLP consistir√° en ajustar estos par√°metros hasta lograr resultados aceptables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815abd3e",
   "metadata": {},
   "source": [
    "### Funciones de Activaci√≥n\n",
    "\n",
    "Si bien existen m√∫ltiples funciones de activaci√≥n, el trabajo pr√°ctico requiere dos en particular:\n",
    "\n",
    "- Lineal.\n",
    "- Sigmoidal.\n",
    "\n",
    "![Funciones de activaci√≥n](assets/activation_functions.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9337ee",
   "metadata": {},
   "source": [
    "### Regla de Aprendizaje\n",
    "\n",
    "Se debe elegir la regla de aprendizaje o _loss function_ a utilizar.\n",
    "Hilera & Martinez presentan la regla _Least Mean Squared_ o _regla delta_:\n",
    "\n",
    "$$\n",
    "\\epsilon_k^2 = \\frac{1}{2L} \\sum_{k=1}^L (d_k - s_k)^2\n",
    "$$\n",
    "\n",
    "\n",
    "mientras que Prince presenta una funci√≥n _Least Squares_ muy similar que omite el coeficiente constante:\n",
    "\n",
    "$$\n",
    "L[\\phi] = \\sum_{i=1}^I (y_i - f[X_i, \\phi])^2\n",
    "$$\n",
    "\n",
    "Ambas consisten en comparar la salida obtenida contra la deseada para obtener el costo o p√©rdida.\n",
    "El costo se deber√≠a reducir en cada iteraci√≥n del entrenamiento del MLP a medida que se ajustan los par√°metros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50978cd",
   "metadata": {},
   "source": [
    "### Momento\n",
    "\n",
    "El _momento_ es una modificaci√≥n al algoritmo _backpropagation_ del gradiente descendiente para suavizar el progreso del algoritmo y evitar oscilaciones.\n",
    "Matem√°ticamente es un coeficiente $\\beta$ que se agrega para considerar el valor de la iteraci√≥n anterior de un par√°metro al momento de calcular su nuevo valor en la iteraci√≥n siguiente.\n",
    "\n",
    "Hilera & Martinez lo presentan como:\n",
    "\n",
    "$$\n",
    "w_{ji} (t+1) = w_{ji}(t) \\alpha \\delta_{pj}y_{pi} + \\underbrace {\\beta (w_{ji}(t) - w_{ji} (t-1))}_\\text{T√©rmino momento} \\\\\n",
    "$$\n",
    "\n",
    "mientras que Prince lo presenta como:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{m}_{t+1} &\\leftarrow \\beta \\cdot \\mathbf{m}_t \n",
    "  + (1 - \\beta) \\sum_{i \\in \\mathcal{B}_t} \n",
    "  \\frac{\\partial \\ell_i[\\boldsymbol{\\phi}_t]}{\\partial \\boldsymbol{\\phi}}, \\\\[6pt]\n",
    "\\boldsymbol{\\phi}_{t+1} &\\leftarrow \n",
    "  \\boldsymbol{\\phi}_t - \\alpha \\cdot \\mathbf{m}_{t+1},\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b908af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters initialized:\n",
      "  W1 shape: (10, 100), b1 shape: (10,)\n",
      "  W2 shape: (5, 10), b2 shape: (5,)\n",
      "  W3 shape: (3, 5), b3 shape: (3,)\n",
      "  Total parameters: 1083\n"
     ]
    }
   ],
   "source": [
    "SIZE_INPUTS = 100\n",
    "SIZE_H1 = 10\n",
    "SIZE_H2 = 5\n",
    "SIZE_OUTPUTS = 3\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    \"\"\"\n",
    "    Multilayer Perceptron implementation for pattern classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        architecture: List[int] = [100, 10, 5, 3],\n",
    "        learning_rate: float = 0.1,\n",
    "        momentum: float = 0.0,\n",
    "        activation_type: Literal[\"sigmoid\", \"linear\"] = \"sigmoid\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the MLP with given hyperparameters.\n",
    "\n",
    "        Args:\n",
    "            architecture: List with the size of each layer [input, hidden1, hidden2, output].\n",
    "            learning_rate: Learning rate for gradient descent (0 < lr <= 1).\n",
    "            momentum: Momentum coefficient for parameter updates (0 <= momentum < 1).\n",
    "            activation_type: Activation function type.\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.activation_type = activation_type\n",
    "\n",
    "        self.architecture = architecture\n",
    "        self.input_size = architecture[0]\n",
    "        self.hidden1_size = architecture[1]\n",
    "        self.hidden2_size = architecture[2]\n",
    "        self.output_size = architecture[3]\n",
    "\n",
    "        self._initialize_parameters()\n",
    "        self._initialize_momentum()\n",
    "\n",
    "    def _initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize weights and biases using Xavier initialization, where each\n",
    "        parameter will be drawn from a normal distribution with mean of `0` and\n",
    "        a standard deviation of `sqrt(2 / (input_layer_size + output_layer_size))`.\n",
    "        This helps prevent vanishing or exploding gradients.\n",
    "        \"\"\"\n",
    "        # Initialize layer 1 parameters\n",
    "        std1 = np.sqrt(2.0 / (self.input_size + self.hidden1_size))\n",
    "        self.W1 = RNG.normal(0, std1, (self.hidden1_size, self.input_size))\n",
    "        self.b1 = np.zeros(self.hidden1_size)\n",
    "\n",
    "        # Initialize layer 2 parameters\n",
    "        std2 = np.sqrt(2.0 / (self.hidden1_size + self.hidden2_size))\n",
    "        self.W2 = RNG.normal(0, std2, (self.hidden2_size, self.hidden1_size))\n",
    "        self.b2 = np.zeros(self.hidden2_size)\n",
    "\n",
    "        # Initialize output layer parameters\n",
    "        std3 = np.sqrt(2.0 / (self.hidden2_size + self.output_size))\n",
    "        self.W3 = RNG.normal(0, std3, (self.output_size, self.hidden2_size))\n",
    "        self.b3 = np.zeros(self.output_size)\n",
    "\n",
    "        print(\"Parameters initialized:\")\n",
    "        print(f\"  W1 shape: {self.W1.shape}, b1 shape: {self.b1.shape}\")\n",
    "        print(f\"  W2 shape: {self.W2.shape}, b2 shape: {self.b2.shape}\")\n",
    "        print(f\"  W3 shape: {self.W3.shape}, b3 shape: {self.b3.shape}\")\n",
    "        print(\n",
    "            f\"  Total parameters: {self.W1.size + self.b1.size + self.W2.size + self.b2.size + self.W3.size + self.b3.size}\"\n",
    "        )\n",
    "\n",
    "    def _initialize_momentum(self):\n",
    "        \"\"\"\n",
    "        Initialize momentum terms for parameter updates.\n",
    "        These store the previous update directions to add momentum.\n",
    "        \"\"\"\n",
    "        self.dW1_prev = np.zeros_like(self.W1)\n",
    "        self.db1_prev = np.zeros_like(self.b1)\n",
    "        self.dW2_prev = np.zeros_like(self.W2)\n",
    "        self.db2_prev = np.zeros_like(self.b2)\n",
    "        self.dW3_prev = np.zeros_like(self.W3)\n",
    "        self.db3_prev = np.zeros_like(self.b3)\n",
    "\n",
    "    def get_activation_function(self):\n",
    "        \"\"\"Return the activation function based on the activation type.\"\"\"\n",
    "        if self.activation_type == \"sigmoid\":\n",
    "            return lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif self.activation_type == \"linear\":\n",
    "            return lambda x: x\n",
    "\n",
    "    def feedforward(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Perform forward propagation through the network.\n",
    "\n",
    "        Args:\n",
    "            X: Array of 100 values (0 or 1) representing the input data from a sample.\n",
    "        Returns:\n",
    "            Array of 3 items with the predictions for classes 'b', 'd' and 'f'.\n",
    "        \"\"\"\n",
    "        a = self.get_activation_function()\n",
    "\n",
    "        # Forward pass from input layer to hidden layer 1\n",
    "        h1 = a(self.b1 + np.dot(self.W1, X.T).T)\n",
    "\n",
    "        # Forward pass from hidden layer 1 to hidden layer 2\n",
    "        h2 = a(self.b2 + np.dot(self.W2, h1.T).T)\n",
    "\n",
    "        # Forward pass from hidden layer 2 to output layer\n",
    "        y = self.b3 + np.dot(self.W3, h2.T).T\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d21542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing feedforward with sample data...\n",
      "Input pattern:\n",
      "0 0 0 0 0 0 0 0 0 0\n",
      "0 0 \u001b[1;92m1\u001b[0m 0 0 0 0 0 0 0\n",
      "0 0 \u001b[1;92m1\u001b[0m 0 0 0 0 0 0 0\n",
      "0 0 \u001b[1;92m1\u001b[0m 0 0 0 0 0 0 0\n",
      "0 0 \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m 0 0 0\n",
      "0 0 \u001b[1;92m1\u001b[0m 0 0 0 0 \u001b[1;92m1\u001b[0m 0 0\n",
      "0 0 \u001b[1;92m1\u001b[0m 0 0 0 0 \u001b[1;92m1\u001b[0m 0 0\n",
      "0 0 \u001b[1;92m1\u001b[0m 0 0 0 0 \u001b[1;92m1\u001b[0m 0 0\n",
      "0 0 \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m \u001b[1;92m1\u001b[0m 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0\n",
      "Single sample output:\n",
      "[ 0.71048979 -0.3419544  -0.58371697]\n",
      "Multiple samples output:\n",
      "[[ 0.71048979 -0.3419544  -0.58371697]\n",
      " [ 0.69937229 -0.34897471 -0.57442121]\n",
      " [ 0.70946331 -0.37255956 -0.58141278]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing feedforward with sample data...\")\n",
    "\n",
    "# Test with a single sample\n",
    "sample_pattern = generate_sample(\"b\", 0.0)\n",
    "print(\"Input pattern:\")\n",
    "print_sample(sample_pattern)\n",
    "\n",
    "output_single = mlp.feedforward(sample_pattern)\n",
    "print(\"Single sample output:\")\n",
    "print(output_single)\n",
    "\n",
    "# Test with multiple samples\n",
    "multiple_patterns = np.array(\n",
    "    [\n",
    "        generate_sample(\"b\", 0.0),\n",
    "        generate_sample(\"d\", 0.0),\n",
    "        generate_sample(\"f\", 0.0),\n",
    "    ]\n",
    ")\n",
    "output_multiple = mlp.feedforward(multiple_patterns)\n",
    "print(\"Multiple samples output:\")\n",
    "print(output_multiple)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
